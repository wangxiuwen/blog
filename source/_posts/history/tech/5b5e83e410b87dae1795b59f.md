---
title: 定时清理spark work 目录
date: 2018-07-30 11:20:04
tags: ["tech","技术"]
author: wangxiuwen
categories: ["技术"]
layout: post
---

使用spark standalone模式执行任务，每提交一次任务，在每个节点work目录下都会生成一个文件夹，最终导致 spark work 目录占用过多，磁盘报警

```
	vim spark-env.sh
	export SPARK_WORKER_OPTS="  
	-Dspark.worker.cleanup.enabled=true  # 是否开启自动清理
	-Dspark.worker.cleanup.interval=60 # 清理周期，每隔多长时间清理一次，单位秒
	-Dspark.worker.cleanup.appDataTtl=60"  # 保留最近多长时间的数据
```