---
title: elasticsearch安装配置及中文分词
date: 2015-12-28 02:17:55
tags: ["tech","技术","elasticsearch"]
author: wangxiuwen
categories: ["技术"]
layout: post
---

原文地址
http://www.nosqldb.cn/1368777502778.html


ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。支持通过HTTP使用JSON进行数据索引。 

　　我们建立一个网站或应用程序，并要添加搜索功能，令我们受打击的是：搜索工作是很难的。我们希望我们的搜索解决方案要快，我们希望有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP的索引数据，我们希望我们的搜索服务器始终可用，我们希望能够一台开始并扩展到数百，我们要实时搜索，我们要简单的多租户，我们希望建立一个云的解决方案。Elasticsearch旨在解决所有这些问题和更多的。

安装
　　以windows操作系统和ES0.19.7版本为例：


　　①下载elasticsearch-0.19.7.zip


　　②直接解压至某目录，设置该目录为ES_HOME环境变量


　　③安装JDK，并设置JAVA_HOME环境变量


　　④在windows下，运行 %ES_HOME%\bin\elasticsearch.bat即可运行

分布式搜索elasticsearch单机与服务器环境搭建

      先到http://www.elasticsearch.org/download/下载最新版的elasticsearch运行包，本文写时最新的是0.19.1，作者是个很勤快的人，es的更新很频繁，bug修复得很快。下载完解开有三个包:bin是运行的脚本，config是设置文件，lib是放依赖的包。如果你要装插件的话就要多新建一个plugins的文件夹，把插件放到这个文件夹中。

1.单机环境：

单机版的elasticsearch运行很简单，linux下直接 bin/elasticsearch就运行了，windows运行bin/elasticsearch.bat。如果是在局域网中运行elasticsearch集群也是很简单的，只要cluster.name设置一致，并且机器在同一网段下，启动的es会自动发现对方，组成集群。

2.服务器环境：

如果是在服务器上就可以使用elasticsearch-servicewrapper这个es插件，它支持通过参数，指定是在后台或前台运行es，并且支持启动，停止，重启es服务（默认es脚本只能通过ctrl+c关闭es）。使用方法是到https://github.com/elasticsearch/elasticsearch-servicewrapper下载service文件夹，放到es的bin目录下。下面是命令集合：
bin/service/elasticsearch +
console 在前台运行es
start 在后台运行es
stop 停止es
install 使es作为服务在服务器启动时自动启动
remove 取消启动时自动启动

在service目录下有个elasticsearch.conf配置文件，主要是设置一些java运行环境参数，其中比较重要的是下面的

参数：

#es的home路径，不用用默认值就可以
set.default.ES_HOME=<Path to ElasticSearch Home>

#分配给es的最小内存
set.default.ES_MIN_MEM=256

#分配给es的最大内存
set.default.ES_MAX_MEM=1024


# 启动等待超时时间（以秒为单位）
wrapper.startup.timeout=300

# 关闭等待超时时间（以秒为单位）

wrapper.shutdown.timeout=300

# ping超时时间(以秒为单位)

wrapper.ping.timeout=300

安装插件
　　以head插件为例：


　　联网时，直接运行%ES_HOME%\bin\plugin -install mobz/elasticsearch-head


　　不联网时，下载elasticsearch-head的zipball的master包，把内容解压到%ES_HOME%\plugin\head\_site目录下，


　　安装完成，重启服务，在浏览器打开 http://localhost:9200/_plugin/head/ 即可

ES概念
　　cluster


　　代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。


　　shards


　　代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。


　　replicas


　　代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当个某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。


　　recovery


　　代表数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。


　　river


　　代表es的一个数据源，也是其它存储方式（如：数据库）同步数据到es的一个方法。它是以插件方式存在的一个es服务，通过读取river中的数据并把它索引到es中，官方的river有couchDB的，RabbitMQ的，Twitter的，Wikipedia的。


　　gateway


　　代表es索引的持久化存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到硬盘。当这个es集群关闭再重新启动时就会从gateway中读取索引数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。


　　discovery.zen


　　代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。


　　Transport


　　代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。

分布式搜索elasticsearch中文分词集成

elasticsearch官方只提供smartcn这个中文分词插件，效果不是很好，好在国内有medcl大神（国内最早研究es的人之一）写的两个中文分词插件，一个是ik的，一个是mmseg的，下面分别介绍下两者的用法，其实都差不多的，先安装插件，命令行：
安装ik插件：

plugin -install medcl/elasticsearch-analysis-ik/1.1.0  

下载ik相关配置词典文件到config目录

cd config  
wget http://github.com/downloads/medcl/elasticsearch-analysis-ik/ik.zip --no-check-certificate  
unzip ik.zip  
rm ik.zip  
安装mmseg插件：

bin/plugin -install medcl/elasticsearch-analysis-mmseg/1.1.0  
下载相关配置词典文件到config目录

cd config  
wget http://github.com/downloads/medcl/elasticsearch-analysis-mmseg/mmseg.zip --no-check-certificate  
unzip mmseg.zip  
rm mmseg.zip  
分词配置

ik分词配置，在elasticsearch.yml文件中加上

index:  
  analysis:                     
    analyzer:        
      ik:  
          alias:   
          type: org.elasticsearch.index.analysis.IkAnalyzerProvider  
或

index.analysis.analyzer.ik.type : “ik”  
这两句的意义相同
mmseg分词配置，也是在在elasticsearch.yml文件中

index:  
  analysis:  
    analyzer:  
      mmseg:  
          alias:   
          type: org.elasticsearch.index.analysis.MMsegAnalyzerProvider  
或

index.analysis.analyzer.default.type : "mmseg"  
mmseg分词还有些更加个性化的参数设置如下

index:  
  analysis:  
    tokenizer:  
      mmseg_maxword:  
          type: mmseg  
          seg_type: "max_word"  
      mmseg_complex:  
          type: mmseg  
          seg_type: "complex"  
      mmseg_simple:  
          type: mmseg  
          seg_type: "simple"  
这样配置完后插件安装完成，启动es就会加载插件。

定义mapping

在添加索引的mapping时就可以这样定义分词器

{  
   "page":{  
      "properties":{  
         "title":{  
            "type":"string",  
            "indexAnalyzer":"ik",  
            "searchAnalyzer":"ik"  
         },  
         "content":{  
            "type":"string",  
            "indexAnalyzer":"ik",  
            "searchAnalyzer":"ik"  
         }  
      }  
   }  
}  
indexAnalyzer为索引时使用的分词器，searchAnalyzer为搜索时使用的分词器。

java mapping代码如下：

XContentBuilder content = XContentFactory.jsonBuilder().startObject()  
        .startObject("page")  
          .startObject("properties")         
            .startObject("title")  
              .field("type", "string")             
              .field("indexAnalyzer", "ik")  
              .field("searchAnalyzer", "ik")  
            .endObject()   
            .startObject("code")  
              .field("type", "string")           
              .field("indexAnalyzer", "ik")  
              .field("searchAnalyzer", "ik")  
            .endObject()       
          .endObject()  
         .endObject()  
       .endObject()  
定义完后操作索引就会以指定的分词器来进行分词。

 附：

ik分词插件项目地址：https://github.com/medcl/elasticsearch-analysis-ik

mmseg分词插件项目地址：https://github.com/medcl/elasticsearch-analysis-mmseg

如果觉得配置麻烦，也可以下载个配置好的es版本，地址如下：https://github.com/medcl/elasticsearch-rtf



elasticsearch的基本用法

最大的特点： 
1. 数据库的 database, 就是  index 
2. 数据库的 table,  就是 tag 
3. 不要使用browser， 使用curl来进行客户端操作.  否则会出现 java heap ooxx... 

curl:  -X 后面跟 RESTful ：  GET, POST ... 
-d 后面跟数据。 (d = data to send) 

1. create:  

指定 ID 来建立新记录。 （貌似PUT， POST都可以） 
$ curl -XPOST localhost:9200/films/md/2 -d ' 
{ "name":"hei yi ren", "tag": "good"}' 

使用自动生成的 ID 建立新纪录： 
$ curl -XPOST localhost:9200/films/md -d ' 
{ "name":"ma da jia si jia3", "tag": "good"}' 

2. 查询： 
2.1 查询所有的 index, type: 
$ curl localhost:9200/_search?pretty=true 

2.2 查询某个index下所有的type: 
$ curl localhost:9200/films/_search 

2.3 查询某个index 下， 某个 type下所有的记录： 
$ curl localhost:9200/films/md/_search?pretty=true 

2.4 带有参数的查询：  
$ curl localhost:9200/films/md/_search?q=tag:good 
{"took":7,"timed_out":false,"_shards":{"total":5,"successful":5,"failed":0},"hits":{"total":2,"max_score":1.0,"hits":}} 

2.5 使用JSON参数的查询： （注意 query 和 term 关键字） 
$ curl localhost:9200/film/_search -d ' 
{"query" : { "term": { "tag":"bad"}}}' 

3. update  
$ curl -XPUT localhost:9200/films/md/1 -d { ...(data)... } 

4. 删除。 删除所有的： 
$ curl -XDELETE localhost:9200/films 
看了这篇文章的人还看了：
Elasticsearch集成中文分词
elasticsearch的中文分词插件ansj
分布式搜索elasticsearch中文分词集成
elasticsearch安装配置及中文分词
ElasticSearch carrot2插件、ik分词插件更新
ElasticSearch开发环境搭建
相关搜索：        elasticsearch安装        elasticsearch配置        elasticsearch中文分词


