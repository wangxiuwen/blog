---
title: spark 基础
date: 2017-12-27 10:49:24
tags: ["tech","技术"]
author: wangxiuwen
categories: ["技术"]
layout: post
---

spark-default.conf 参数

```
	spark.yarn.historyServer.address=test:18080
	spark.history.ui.port=18080
	spark.eventLog.enabled=true
	spark.eventLog.dir=hdfs://test-1:9000/tmp/spark/events
	
	# 无需每次上传jar包
	spark.yarn.archive=hdfs:///system/spark/spark-libs.jar
```

`spark-env.sh`:

```
	export HADOOP_CONF_DIR=/usr/local/hadoop/hadoop-2.7.3/etc/hadoop
```

启动

	bin/spark-shell --master yarn --deploy-mode client

>spark-shell 内部调用了 spark-submit

yarn 模式查看日志

	bin/yarn logs --applicationId application_xxxxx

>提交作业和运行命令的用户必须一致，否则拉不到日志

内存配置

```
  <property>
  	<name>yarn.nodemanager.vmem-pmem-ratio</name>
  	<value>10</value>
  </property>
```

```
spark-submit --excutor-memory 10G --conf  "spark.yarn.executor.memoryOverhead=2048"	
```

hdfs 查看 一个文件下的 block 个数
```
	hdfs fsck
```

partque 文件


--master 选项为分布式的集群指定  `master URL`,  local 为 单进程启动， local[N] 为N个进程启动，测试的时候应该指定为 local
```
./bin/spark-shell --master local[2]

./bin/spark-shell --master yarn --deploy-mode client --verbose
```

查看 hdfs 一个文件有几个 block

```
	./bin/hdfs fsck /data/opt/test.txt --files --blocks -locations
```